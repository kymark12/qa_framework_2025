# ğŸ§ª Marky 2025 QA Automation Framework

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Pytest](https://img.shields.io/badge/pytest-8.0.0-green.svg)](https://docs.pytest.org/)
[![Playwright](https://img.shields.io/badge/playwright-1.41.0-orange.svg)](https://playwright.dev/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Live Dashboard](https://img.shields.io/badge/Dashboard-Live-success.svg)](https://appframework2025-mupyhx5frbro3tvwrmuxaq.streamlit.app/)

A modern, scalable test automation framework demonstrating professional QA engineering practices. This framework showcases expertise in API testing, UI automation, and comprehensive test reporting with CI/CD integration.

> **âš ï¸ Disclaimer:** This repository is for educational and portfolio demonstration purposes only.
> 
> **Test Applications Used:**
> - **UI Testing**: [SauceDemo](https://www.saucedemo.com/) - An open-source demo application created by Sauce Labs specifically for testing practice
> - **API Testing**: [JSONPlaceholder](https://jsonplaceholder.typicode.com/) - A free fake REST API for testing and prototyping
> 
> Both applications are publicly available and explicitly designed for testing practice and educational purposes.

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Live Dashboard](#-live-dashboard)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Getting Started](#-getting-started)
- [Running Tests](#-running-tests)
- [Test Reports](#-test-reports)
- [CI/CD Integration](#-cicd-integration)
- [Best Practices](#-best-practices)
- [Contact](#-contact)

---

## âœ¨ Features

- **Multi-Layer Testing**: API, UI (E2E), and Unit tests
- **Modern Tools**: Playwright for UI automation, Pytest for test execution
- **Professional Reporting**: Allure reports with detailed test analytics
- **Live Dashboard**: Real-time test results visualization with Streamlit
- **CI/CD Ready**: GitHub Actions workflow for automated testing
- **Scalable Architecture**: Modular design with fixtures and reusable components
- **Best Practices**: Page Object Model, fixture management, test isolation
- **Type Safety**: Python type hints for better code quality
- **Version Control**: Pinned dependencies for reproducible environments

---

## ğŸ›  Tech Stack

| Category | Technology |
|----------|-----------|
| **Language** | Python 3.12+ |
| **Test Framework** | Pytest 8.0.0 |
| **UI Automation** | Playwright 1.41.0 |
| **API Testing** | Requests 2.31.0 |
| **Reporting** | Allure 2.13.2 + Streamlit Dashboard |
| **Dashboard** | Streamlit 1.31.0 |
| **CI/CD** | GitHub Actions |
| **Package Management** | virtualenv |

---

## ğŸ“ Project Structure
```
marky_2025_qa_framework/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/          # CI/CD pipeline configurations
â”‚       â”œâ”€â”€ ci.yml          # Main test execution workflow
â”‚       â””â”€â”€ cleanup-reports.yml
â”œâ”€â”€ .streamlit/             # Streamlit configuration
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ fixtures/               # Test data and fixtures
â”œâ”€â”€ reports/                # Generated test reports
â”‚   â”œâ”€â”€ report.json         # Latest test results (JSON)
â”‚   â””â”€â”€ allure-results/     # Allure report data
â”œâ”€â”€ src/
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ pytest_streamlit_dashboard.py  # Live dashboard
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ api/                # API test suite
â”‚   â”‚   â””â”€â”€ test_api.py 
â”‚   â”œâ”€â”€ ui/                 # UI/E2E test suite
â”‚   â”‚   â””â”€â”€ test_login.py 
â”‚   â””â”€â”€ unit/               # Unit test suite
â”œâ”€â”€ conftest.py             # Pytest fixtures and configuration
â”œâ”€â”€ pytest.ini              # Pytest settings
â”œâ”€â”€ requirements.txt        # Dashboard dependencies
â”œâ”€â”€ requirements-dev.txt    # Development/testing dependencies
â””â”€â”€ README.md 
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.12 or higher
- Git
- Virtual environment tool (virtualenv)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/marky_2025_qa_framework.git
   cd marky_2025_qa_framework
   ```

2. **Create and activate virtual environment**
   ```bash
   python -m venv .venv
   
   # On Windows
   .venv\Scripts\activate
   
   # On macOS/Linux
   source .venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements-dev.txt

   # For dashboard only
   pip install -r requirements.txt
   ```

4. **Install Playwright browsers**
   ```bash
   playwright install chromium
   ```

---

## ğŸ§ª Running Tests

### Run All Tests
```bash
pytest
```
### API tests only
```bash
pytest tests/api/
```
### UI tests only
```bash
pytest tests/ui/
```
### Unit tests only
```bash
pytest tests/unit/
```
### Run Tests by Markers
```bash
# E2E tests
pytest -m e2e

# Smoke tests
pytest -m smoke

# Slow tests
pytest -m slow
```

### Run with Verbose 
```bash
pytest -v
```

### Run with Coverage
```bash
pytest --cov=src --cov-report=html
```

---

## ğŸ“Š Test Reports

### 1. Live Streamlit Dashboard

**[View Live Dashboard â†’](https://appframework2025-mupyhx5frbro3tvwrmuxaq.streamlit.app/)**

Automatically updated with every test run via CI/CD pipeline.

### 2. Allure Reports

#### Generate Allure Reports

```bash
# Run tests with Allure
pytest --alluredir=./reports/allure-results

# View the report
allure serve ./reports/allure-results
```

### 3. JSON Report

```bash
# Generate JSON report (automatically created by pytest)
pytest --json-report --json-report-file=./reports/report.json

# View raw JSON
cat reports/report.json
```

The framework automatically generates:
1. âœ… Test execution summaries
2. ğŸ“ Detailed step-by-step logs
3. ğŸ“¸ Screenshots on failures (UI tests)
4. ğŸŒ API request/response details
5. ğŸ“ˆ Trend analysis over multiple runs

---

## ğŸ”„ CI/CD Integration

This framework includes **GitHub Actions workflows** for continuous testing:

### Main CI Workflow (`.github/workflows/ci.yml`)

- âœ… Automated test execution on push/PR
- âœ… Playwright browser installation
- âœ… Test execution with retry logic (2 retries)
- âœ… Automatic report generation and archiving
- âœ… Report publishing to `reports` branch
- âœ… Artifact uploads (Allure results, JSON reports, screenshots)

### Report Cleanup Workflow (`.github/workflows/cleanup-reports.yml`)

- ğŸ—‘ï¸ Scheduled cleanup of old archived reports (weekly)
- ğŸ”¢ Keeps the 20 most recent reports
- ğŸ“¦ Prevents repository bloat

### Dashboard Auto-Update

The Streamlit dashboard automatically:
1. Fetches the latest `report.json` from the `reports` branch
2. Updates visualizations in real-time
3. Shows current test execution status

---

## ğŸ¯ Best Practices Demonstrated

- **Test Organization**: Clear separation of API, UI, and unit tests
- **Fixture Management**: Reusable fixtures in conftest.py
- **Configuration Management**: Environment-specific configs
- **Page Object Model**: Maintainable UI test structure
- **API Client Pattern**: Centralized API interaction logic
- **Version Pinning**: Reproducible dependency management
- **Documentation**: Comprehensive inline and README docs
- **CI/CD Integration**: Automated testing pipeline
- **Reporting**: Professional test reports with Allure
- **Code Quality**: Clean, readable, and maintainable code
- **Failure Tracking**: Intentional failure scenarios for comprehensive testing

---

## ğŸ“š Key Testing Concepts

### API Testing

- RESTful API endpoint validation
- Request/response verification
- Authentication handling
- Error handling and edge cases

### UI Testing

- End-to-end user workflows
- Cross-browser compatibility
- Page Object Model implementation
- Element interaction strategies

### Test Data Management

- Fixture-based data provisioning
- Environment-specific configurations
- Test isolation and cleanup

## ğŸ¤ Contributing

This is a portfolio project, but feedback and suggestions are welcome! Feel free to:

- Open an issue for discussions
- Fork the repository for your own learning
- Reach out with questions or suggestions

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Contact

Mark Ivan Berbenzana**

- ğŸ“§ Email: marky.berbenzana@gmail.com
- ğŸ’¼ LinkedIn: [Mark Ivan Berbenzana](https://www.linkedin.com/in/mark-ivan-berbenzana-841093bb/)
- ğŸ™ GitHub: https://github.com/kymark12
- ğŸ“Š Live Dashboard: [View Test Results](https://appframework2025-mupyhx5frbro3tvwrmuxaq.streamlit.app/)

---

## ğŸ™ Acknowledgments

- Pytest team for the excellent testing framework
- Playwright team for modern browser automation
- Allure for beautiful test reporting
- Streamlit for interactive dashboard capabilities
- Open source community for continuous inspiration

---

## ğŸ“¸ Dashboard Preview

Visit the **[Live Dashboard](https://appframework2025-mupyhx5frbro3tvwrmuxaq.streamlit.app/)** to see:
- Real-time test metrics
- Failure analysis with detailed information
- Performance insights and slowest tests
- Comprehensive test coverage visualization

---

â­ If you find this project helpful, please consider giving it a star!

**Last Updated**: December 2025